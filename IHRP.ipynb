{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Import Library"
      ],
      "metadata": {
        "id": "FAcHOLg7VHIm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OcrtRf3rVD7T"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Helper Functions"
      ],
      "metadata": {
        "id": "c-N6h4UWVE8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_ifn(value):\n",
        "    # Generate a random membership degree between 0 and value/4\n",
        "    # m = np.random.uniform(0, value/4)\n",
        "\n",
        "    # # Ensure the non-membership degree satisfies m + n <= 1\n",
        "    # n = np.random.uniform(0, 1 - m)\n",
        "    ifns = {\n",
        "        \"0\":(0.10,0.90),\n",
        "        \"1\":(0.20,0.65),\n",
        "        \"2\":(0.30,0.55),\n",
        "        \"3\":(0.50,0.50),\n",
        "        \"4\":(0.65,0.25),\n",
        "        \"5\":(0.80,0.05),\n",
        "        \"6\":(0.90,0.10)\n",
        "    }\n",
        "    return ifns[str(value)]\n",
        "\n",
        "def m_operation(pair1, pair2):\n",
        "    a1, b1 = pair1\n",
        "    a2, b2 = pair2\n",
        "    return (min(a1, a2), max(b1, b2))\n",
        "\n",
        "def M_operation(pair1, pair2):\n",
        "    a1, b1 = pair1\n",
        "    a2, b2 = pair2\n",
        "    return (max(a1, a2), min(b1, b2))\n",
        "\n",
        "\n",
        "def dist(pair1, pair2):\n",
        "    a1, b1 = pair1\n",
        "    a2, b2 = pair2\n",
        "    h1 = 1 - (a1 + b1)\n",
        "    h2 = 1 - (a2 + b2)\n",
        "\n",
        "    term1 = (abs(2*(a1 - a2) - (b1 - b2)) / 3) * (1 - (h1 + h2) / 2)\n",
        "    term2 = (abs(2*(b1 - b2) - (a1 - a2)) / 3) * ((h1 + h2) / 2)\n",
        "\n",
        "    return term1 + term2"
      ],
      "metadata": {
        "id": "IJVcmsu9VbxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Input Experts Data"
      ],
      "metadata": {
        "id": "ZPE6ZmI4VkkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('input.csv')\n",
        "\n",
        "# Calculate n\n",
        "n = int(np.sqrt(df.shape[0]))\n",
        "k = df.shape[1] - 1\n",
        "# # Initialize the list of expert matrices\n",
        "expert_matrices = []\n",
        "\n",
        "# Iterate over the columns of the DataFrame\n",
        "for i in range(1, df.shape[1]):\n",
        "    # Convert the column values to a list\n",
        "    column_values = df.iloc[:, i].tolist()\n",
        "\n",
        "    # Reshape the list into an n*n matrix\n",
        "    matrix = np.reshape(column_values, (n, n),order='F')\n",
        "    matrix = matrix.T\n",
        "    # Add the matrix to the list\n",
        "    expert_matrices.append(matrix)\n",
        "\n",
        "    # Convert matrices to IFN matrices\n",
        "ifn_matrices = []\n",
        "\n",
        "for matrix in expert_matrices:\n",
        "    ifn_matrix = np.array([[generate_ifn(value) for value in row] for row in matrix])\n",
        "    ifn_matrices.append(ifn_matrix)\n",
        "\n",
        "# Write the matrices and IFN matrices to a file\n",
        "with open(\"solution.txt\", \"w\") as file:\n",
        "    for i, (matrix, ifn_matrix) in enumerate(zip(expert_matrices, ifn_matrices), 1):\n",
        "        file.write(f\"Expert Matrix {i}:\\n\")\n",
        "        for row in matrix:\n",
        "            file.write(\" \".join(map(str, row)) + \"\\n\")\n",
        "        file.write(\"\\n\")\n",
        "\n",
        "        file.write(f\"Expert {i} IFN Matrix :\\n\")\n",
        "        for row in ifn_matrix:\n",
        "            file.write(\" \".join([f\"({m:.2f}, {n:.2f})\" for m, n in row]) + \"\\n\")\n",
        "        file.write(\"\\n\")\n",
        "\n",
        "print(\"Matrices and IFN matrices have been written to 'solution.txt'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMKbuaP2VreL",
        "outputId": "b106193c-2e0a-426e-c739-58f62fa7e19a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrices and IFN matrices have been written to 'solution.txt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# priority_parameter=float(input(\"Enter the Priority Parameter: \"))\n",
        "priority_parameter=0.5"
      ],
      "metadata": {
        "id": "SdHj0M5oWErF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate IFPIO  Matrix"
      ],
      "metadata": {
        "id": "uVk6BnsMWUbX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IFPIO = np.zeros((n, n, 2))  # Initialize a nxn matrix with pairs\n",
        "for i in range(n):\n",
        "    for j in range(n):\n",
        "        result = [1, 1]  # Initialize with neutral element for the $ operation\n",
        "        for ifn_matrix in ifn_matrices:\n",
        "            result = [result[0] * (ifn_matrix[i][j][0]**(1/k)),result[1]*((1-ifn_matrix[i][j][1])**(1/k))]\n",
        "        IFPIO[i][j] = [result[0],1-result[1]]  # Take the average\n",
        "\n",
        "# Append the IFPIO matrix to the solution.txt file\n",
        "with open(\"solution.txt\", \"a\") as file:\n",
        "    file.write(\"IFPIO Matrix (Intuitionistic Fuzzy Positive Ideal Opinion Matrix):\\n\")\n",
        "    for row in IFPIO:\n",
        "        file.write(\" \".join([f\"({m:10.5f}, {n:10.5f})\" for m, n in row]) + \"\\n\")\n",
        "    file.write(\"\\n\")\n",
        "\n",
        "print(\"IFPIO matrix has been appended to 'solution.txt'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sg2ftrZiWkAD",
        "outputId": "289d1625-6eff-430e-e5cf-f78b04771a42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IFPIO matrix has been appended to 'solution.txt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate IFNIO Matrice"
      ],
      "metadata": {
        "id": "mZWtHZ7GWyGR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the IFNIO matrix by swapping the pairs from the IFPIO matrix\n",
        "IFNIO = np.array([[(b, a) for a, b in row] for row in IFPIO])\n",
        "\n",
        "# Append the IFNIO matrix to the solution.txt file\n",
        "with open(\"solution.txt\", \"a\") as file:\n",
        "    file.write(\"IFNIO Matrix (Intuitionistic Fuzzy Negative Ideal Opinion Matrix):\\n\")\n",
        "    for row in IFNIO:\n",
        "        file.write(\" \".join([f\"({m:10.5f}, {n:10.5f})\" for m, n in row]) + \"\\n\")\n",
        "    file.write(\"\\n\")\n",
        "\n",
        "print(\"IFNIO matrix has been appended to 'solution.txt'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrSR6Rf6W3PW",
        "outputId": "2d4f15c4-417c-44cd-ec5e-cde8d121a3cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IFNIO matrix has been appended to 'solution.txt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate IFLNIO Matrix"
      ],
      "metadata": {
        "id": "z_CvLbTLXA8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the IFLNIO matrix using the m operation\n",
        "IFLNIO = np.zeros((n, n, 2))  # Initialize a 5x5 matrix with pairs\n",
        "\n",
        "for i in range(n):\n",
        "    for j in range(n):\n",
        "        result = ifn_matrices[0][i][j]  # Start with the first IFN matrix\n",
        "        for p in range(1, len(ifn_matrices)):\n",
        "            result = m_operation(result, ifn_matrices[p][i][j])\n",
        "        IFLNIO[i][j] = result\n",
        "\n",
        "# Append the IFLNIO matrix to the solution.txt file\n",
        "with open(\"solution.txt\", \"a\") as file:\n",
        "    file.write(\"IFLNIO Matrix (Intuitionistic Fuzzy Left Negative Ideal Opinion Matrix):\\n\")\n",
        "    for row in IFLNIO:\n",
        "        file.write(\" \".join([f\"({m:10.5f}, {n:10.5f})\" for m, n in row]) + \"\\n\")\n",
        "    file.write(\"\\n\")\n",
        "\n",
        "print(\"IFLNIO matrix has been appended to 'solution.txt'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJykfjHfW-nc",
        "outputId": "a37f1e8a-5713-4e62-f968-08c2ca2deaf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IFLNIO matrix has been appended to 'solution.txt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate IFRNIO Matrix"
      ],
      "metadata": {
        "id": "QtGGh9SlXFm1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the IFRNIO matrix using the M operation\n",
        "IFRNIO = np.zeros((n, n, 2))  # Initialize a 5x5 matrix with pairs\n",
        "\n",
        "for i in range(n):\n",
        "    for j in range(n):\n",
        "        result = ifn_matrices[0][i][j]  # Start with the first IFN matrix\n",
        "        for p in range(1, len(ifn_matrices)):\n",
        "            result = M_operation(result, ifn_matrices[p][i][j])\n",
        "        IFRNIO[i][j] = result\n",
        "\n",
        "# Append the IFRNIO matrix to the solution.txt file\n",
        "with open(\"solution.txt\", \"a\") as file:\n",
        "    file.write(\"IFRNIO Matrix (Intuitionistic Fuzzy Right Negative Ideal Opinion Matrix):\\n\")\n",
        "    for row in IFRNIO:\n",
        "        file.write(\" \".join([f\"({m:10.5f}, {n:10.5f})\" for m, n in row]) + \"\\n\")\n",
        "    file.write(\"\\n\")\n",
        "\n",
        "print(\"IFRNIO matrix has been appended to 'solution.txt'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KeOAAa_XQ7A",
        "outputId": "f953b75c-93df-4e9b-ce4a-f7f7351c3caa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IFRNIO matrix has been appended to 'solution.txt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defined List of names of matrix"
      ],
      "metadata": {
        "id": "9hGB7ehUXY3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "matrices_list = [IFPIO, IFNIO, IFLNIO, IFRNIO]\n",
        "matrices_names = [\"IFPIO\", \"IFNIO\", \"IFLNIO\", \"IFRNIO\"]\n",
        "\n",
        "# List of the five IFN matrices\n",
        "ifn_matrices_list = ifn_matrices\n",
        "ifn_matrices_names = [f\"IFN{p+1}\" for p in range(k)]\n",
        "expert_matrices_names = [f\"Expert_{p+1}\" for p in range(k)]\n",
        "# Dictionary to store the distance matrices\n",
        "distance_matrices_dict = {}"
      ],
      "metadata": {
        "id": "HbFshq36Xdop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate distance matrix for all the possible combinations"
      ],
      "metadata": {
        "id": "wI5yiTqmXioF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the distance matrices for all n*k combinations\n",
        "with open(\"solution.txt\", \"a\") as file:\n",
        "    for i, matrix in enumerate(matrices_list):\n",
        "          for j, ifn_matrix in enumerate(ifn_matrices_list):\n",
        "              distance_matrix = np.zeros((n, n))\n",
        "              for x in range(n):\n",
        "                  for y in range(n):\n",
        "                      distance_matrix[x][y] = dist(matrix[x][y], ifn_matrix[x][y])\n",
        "\n",
        "              # Store the distance matrix in the dictionary\n",
        "              key = f\"{matrices_names[i]}_to_{ifn_matrices_names[j]}\"\n",
        "\n",
        "              distance_matrices_dict[key] = distance_matrix\n",
        "\n",
        "              # Append the distance matrix to the solution.txt file\n",
        "              file.write(f\"Distance Matrix between {matrices_names[i]} and {ifn_matrices_names[j]}:\\n\")\n",
        "              for row in distance_matrix:\n",
        "                  file.write(\" \".join([f\"{value:10.5f}\" for value in row]) + \"\\n\")\n",
        "              file.write(\"\\n\")\n",
        "\n",
        "print(\"All distance matrices have been computed and stored.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8Xrpo4rXtpU",
        "outputId": "141cffbd-b4b6-4241-d696-05ac878364d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All distance matrices have been computed and stored.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize DistanceMatrix"
      ],
      "metadata": {
        "id": "jgafMczjYH6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DistanceMatrix = np.zeros((k, 4))"
      ],
      "metadata": {
        "id": "_c--7LNKYLSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate Values for DistanceMatrix"
      ],
      "metadata": {
        "id": "sBJ7udpxYNb_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the values for DistanceMatrix\n",
        "for i, ifn_name in enumerate(ifn_matrices_names):\n",
        "    for j, matrix_name in enumerate(matrices_names):\n",
        "        key = f\"{matrix_name}_to_{ifn_name}\"\n",
        "        DistanceMatrix[i][j] = np.sum(distance_matrices_dict[key])\n",
        "\n",
        "# Append the DistanceMatrix to the solution.txt file\n",
        "with open(\"solution.txt\", \"a\") as file:\n",
        "    file.write(\"DistanceMatrix (Summation of Distance Matrices):\\n\")\n",
        "\n",
        "    # Top boundary\n",
        "    file.write(\"+\" + \"-\" * (len(matrices_names) * 12 + 7) + \"+\\n\")\n",
        "\n",
        "    # Column names with vertical boundaries\n",
        "    file.write(\"|       \" + \" | \".join(matrices_names) + \" |\\n\")\n",
        "\n",
        "    # Separator line\n",
        "    file.write(\"|\" + \"-\" * (len(matrices_names) * 12 + 7) + \"|\\n\")\n",
        "\n",
        "    # Matrix rows with vertical boundaries\n",
        "    for i, row in enumerate(DistanceMatrix):\n",
        "        file.write(\"| \" + expert_matrices_names[i] + \" \" + \" | \".join([f\"{value:10.5f}\" for value in row]) + \" |\\n\")\n",
        "\n",
        "    # Bottom boundary\n",
        "    file.write(\"+\" + \"-\" * (len(matrices_names) * 12 + 7) + \"+\\n\\n\")\n",
        "\n",
        "print(\"DistanceMatrix with a boundary has been appended to 'solution.txt'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9DtZsEEYbuY",
        "outputId": "e2ba3e15-dc6e-4d6a-ea7c-06042f9c6080"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DistanceMatrix with a boundary has been appended to 'solution.txt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate Closeness Coefficient"
      ],
      "metadata": {
        "id": "kHN3rL8fYfCM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "closeness_coefficients = []"
      ],
      "metadata": {
        "id": "c2G363u7YnfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(k):  # For each IFN\n",
        "        numerator = sum(DistanceMatrix[i, j] for j in [1, 2, 3])  # Sum values from IFNIO, IFLNIO, and IFRNIO columns\n",
        "        denominator = sum(DistanceMatrix[i])  # Sum values from all four columns\n",
        "        coefficient = numerator / denominator if denominator != 0 else 0  # Handle potential division by zero\n",
        "        closeness_coefficients.append(coefficient)\n",
        "\n",
        "# Append the closeness coefficients to the solution.txt file\n",
        "with open(\"solution.txt\", \"a\") as file:\n",
        "    file.write(\"Closeness Coefficients for each Expert:\\n\")\n",
        "    for i, coefficient in enumerate(closeness_coefficients):\n",
        "        file.write(f\"{expert_matrices_names[i]}: {coefficient:10.5f}\\n\")\n",
        "    file.write(\"\\n\")\n",
        "\n",
        "print(\"Closeness coefficients have been computed and appended to 'solution.txt'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItZLrqjoYofC",
        "outputId": "bd5bd684-105c-4b7b-b633-0581731c19fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closeness coefficients have been computed and appended to 'solution.txt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate **μ** [degree of membership] , **ν** [degree of non-membership] , **π** [degree of hesitation]\n",
        "\n"
      ],
      "metadata": {
        "id": "w2YfWXVNY8yL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mu_values = []\n",
        "nu_values = []\n",
        "hesitation_values = []\n",
        "\n",
        "# Compute the values for each IFN\n",
        "for i in range(k):\n",
        "    # Compute mu value\n",
        "    denominator = DistanceMatrix[i, 0] + DistanceMatrix[i, 1]\n",
        "    mu = DistanceMatrix[i, 1] / denominator if denominator != 0 else 0\n",
        "    mu_values.append(mu)\n",
        "\n",
        "    # Compute nu value\n",
        "    nu = 1 - closeness_coefficients[i]\n",
        "    nu_values.append(nu)\n",
        "\n",
        "    # Compute hesitation value\n",
        "    hesitation = 1 - (mu + nu)\n",
        "    hesitation_values.append(hesitation)\n",
        "\n",
        "# Append the table to the solution.txt file\n",
        "with open(\"solution.txt\", \"a\") as file:\n",
        "    file.write(\"Table of  μ, ν, and π values for each Expert:\\n\")\n",
        "    file.write(\"IFN     |      μ     |   ν   | π\\n\")\n",
        "    file.write(\"-\" * 50 + \"\\n\")\n",
        "    for i in range(k):\n",
        "        file.write(f\"{expert_matrices_names[i]:<8}| {mu_values[i]:10.5f} | {nu_values[i]:10.5f} | {hesitation_values[i]:10.5f}\\n\")\n",
        "    file.write(\"\\n\")\n",
        "\n",
        "print(\"Table of  μ, ν, and π values has been appended to 'solution.txt'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5YHXQ3uZcRp",
        "outputId": "d66ade3e-752c-487a-a489-dc4417e5428a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Table of  μ, ν, and π values has been appended to 'solution.txt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Weight For Each Expert"
      ],
      "metadata": {
        "id": "Ql0yILCcaBSH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the weights W for each IFN\n",
        "weights = []\n",
        "for i in range(k):\n",
        "    mu = mu_values[i]\n",
        "    nu = nu_values[i]\n",
        "    hesitation = hesitation_values[i]\n",
        "    weight = mu + hesitation * (mu / (mu + nu) if mu + nu != 0 else 0)  # Handle potential division by zero\n",
        "    weights.append(weight)\n",
        "\n",
        "# Compute the normalized weights NW\n",
        "total_weight = sum(weights)\n",
        "normalized_weights = [weight / total_weight if total_weight != 0 else 0 for weight in weights]  # Handle potential division by zero\n",
        "\n",
        "# Append the weights and normalized weights to the solution.txt file\n",
        "with open(\"solution.txt\", \"a\") as file:\n",
        "    file.write(\"Weights (W) and Normalized Weights (NW) for each Expert:\\n\")\n",
        "    file.write(\"Expert     |     W      |     NW\\n\")\n",
        "    file.write(\"-\" * 40 + \"\\n\")\n",
        "    for i in range(k):\n",
        "        file.write(f\"{expert_matrices_names[i] :<8}| {weights[i]:10.5f} | {normalized_weights[i]:10.5f}\\n\")\n",
        "    file.write(\"\\n\")\n",
        "\n",
        "print(\"Weights and normalized weights have been computed and appended to 'solution.txt'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmxJeA5naKHA",
        "outputId": "a70291cc-61fe-4ecd-f2e3-4141cd7d6202"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights and normalized weights have been computed and appended to 'solution.txt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inter-Relationship mining between factors"
      ],
      "metadata": {
        "id": "FGtk-8OTD_H4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining Function for getting weighted IFN matrix"
      ],
      "metadata": {
        "id": "gfGH5l2AF0AQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def multiply_matrix_and_weight(matrix, weight):\n",
        "    \"\"\"\n",
        "    Multiplies each element of the matrix (each IFN) by the weight.\n",
        "    Since the matrix contains tuples, we'll handle the multiplication element-wise for the tuples.\n",
        "    \"\"\"\n",
        "    weighted_matrix = []\n",
        "    for row in matrix:\n",
        "        weighted_row = [(weight * element[0], weight * element[1]) for element in row]\n",
        "        weighted_matrix.append(weighted_row)\n",
        "    return weighted_matrix"
      ],
      "metadata": {
        "id": "6wCvZhRFF5MM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get the weighted IFN matrices"
      ],
      "metadata": {
        "id": "KA512KEzF7uf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "expert_weighted_ifn_matrices = [multiply_matrix_and_weight(matrix, weight) for matrix, weight in zip(ifn_matrices, normalized_weights)]\n",
        "\n",
        "# Writing to the solution file\n",
        "with open('solution.txt', 'a') as file:  # 'a' stands for append mode\n",
        "    file.write(\"\\nExpert Weighted IFN Matrices:\\n\")\n",
        "    for i, matrix in enumerate(expert_weighted_ifn_matrices):\n",
        "        file.write(f\"\\nMatric {i + 1}:\\n\")\n",
        "        for row in matrix:\n",
        "            # Writing each row in a readable format\n",
        "            row_str = ', '.join([f\"({x:.2f}, {y:.2f})\" for x, y in row])\n",
        "            file.write(f\"{row_str}\\n\")\n",
        "\n",
        "print(\"Expert weighted IFN matrices have been written to 'solution.txt'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RlwvYWCF-mW",
        "outputId": "3e0fe221-396a-4e23-9bda-15bf74b65938"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expert weighted IFN matrices have been written to 'solution.txt'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate Intuitionistic Fuzzy Weight Aggregated Inter-influence Matrix (IFWAIIM)"
      ],
      "metadata": {
        "id": "Ifm6hPviIwYm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def aggregate_with_dollar_operation(matrices,weights):\n",
        "    \"\"\"\n",
        "    Aggregate multiple IFN matrices using the '$' operation.\n",
        "    \"\"\"\n",
        "    aggregated_matrix = np.zeros((n,n,2))\n",
        "    for i in range(n):\n",
        "      for j in range(n):\n",
        "        e = 0;\n",
        "        result = [1, 1]  # Initialize with neutral element for the $ operation\n",
        "        for ifn_matrix in ifn_matrices:\n",
        "            result = [result[0] * (ifn_matrix[i][j][0]**(weights[e])),result[1]*((1-ifn_matrix[i][j][1])**weights[e])]\n",
        "            e = e+1\n",
        "        aggregated_matrix[i][j] = [result[0],1-result[1]]  # Take the average\n",
        "    return aggregated_matrix\n",
        "\n",
        "\n",
        "# Calculate the IFWAIIM\n",
        "ifwaiim = aggregate_with_dollar_operation(ifn_matrices,normalized_weights)\n",
        "\n",
        "# Writing to the solution file\n",
        "with open('solution.txt', 'a') as file:  # 'a' stands for append mode\n",
        "    file.write(\"\\nIntuitionistic Fuzzy Weight Aggregated Inter-influence Matrix (IFWAIIM):\\n\")\n",
        "    for row in ifwaiim:\n",
        "        # Writing each row in a readable format\n",
        "        row_str = ', '.join([f\"({x:.2f}, {y:.2f})\" for x, y in row])\n",
        "        file.write(f\"{row_str}\\n\")\n",
        "\n",
        "print(\"IFWAIIM has been written to 'solution.txt'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARwccJSbI2OG",
        "outputId": "a206782e-2287-4b4d-d589-6a6af84af8e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IFWAIIM has been written to 'solution.txt'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate C-IIM (Crisp Inter-Infuence Matrix)"
      ],
      "metadata": {
        "id": "Y_aUu7pDMZ4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_to_crisp_value(ifn):\n",
        "    \"\"\"\n",
        "    Transform an IFN to a crisp value using the formula (mu - nu + 1) / 2.\n",
        "    \"\"\"\n",
        "    mu, nu = ifn\n",
        "    return (mu - nu + 1) / 2\n",
        "\n",
        "def create_ciim(ifwaiim):\n",
        "    \"\"\"\n",
        "    Create the Crisp Inter-Influence Matrix (CIIM) by transforming the IFWAIIM.\n",
        "    \"\"\"\n",
        "    ciim = []\n",
        "    for row in ifwaiim:\n",
        "        crisp_row = [transform_to_crisp_value(ifn) for ifn in row]\n",
        "        ciim.append(crisp_row)\n",
        "    return ciim\n",
        "\n",
        "\n",
        "# Create the CIIM from the IFWAIIM\n",
        "ciim = create_ciim(ifwaiim)\n",
        "\n",
        "# Writing to the solution file\n",
        "with open('solution.txt', 'a') as file:  # 'a' stands for append mode\n",
        "    file.write(\"\\nCrisp Inter-Influence Matrix (CIIM):\\n\")\n",
        "    for row in ciim:\n",
        "        # Writing each row in a readable format\n",
        "        row_str = ', '.join([f\"{value:.2f}\" for value in row])\n",
        "        file.write(f\"{row_str}\\n\")\n",
        "\n",
        "print(\"CIIM has been written to 'solution.txt'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDUh_ndQMfYT",
        "outputId": "6d835a18-f8fa-4602-aefe-1057993c9eb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CIIM has been written to 'solution.txt'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Determine the MAXSUM(m*)"
      ],
      "metadata": {
        "id": "KID6Ui0kOtLu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Find the maximum in each row and sum these maximums\n",
        "m1 = np.max(np.sum(ciim, axis=1))\n",
        "\n",
        "# Step 2: Find the maximum in each column and sum these maximums\n",
        "m2 = np.max(np.sum(ciim, axis=0))\n",
        "\n",
        "# Step 5: Determine the maximum between 'max_row_sum' and 'max_col_sum'\n",
        "max_value_in_ciim = max(m1, m2)\n",
        "\n",
        "    # Writing to the solution file\n",
        "with open('solution.txt', 'a') as file:  # 'a' stands for append mode\n",
        "    file.write(\"\\n========================================\\n\")  # For emphasis and separation\n",
        "    file.write(f\"Maximum Value in CIIM: {max_value_in_ciim:.2f}\\n\")\n",
        "    file.write(\"========================================\\n\")  # For emphasis and separation\n",
        "\n",
        "print(\"Maximum value in CIIM has been written to 'solution.txt'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87IvPpCiOw2O",
        "outputId": "9fd65637-56e7-4210-ba9f-fb85feb882b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum value in CIIM has been written to 'solution.txt'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate N-IIM (Normalized Inter-Infuence Matrix)"
      ],
      "metadata": {
        "id": "2ndy9mzdPI3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_iim = [[value / max_value_in_ciim for value in row] for row in ciim]\n",
        "\n",
        "# Writing to the solution file\n",
        "with open('solution.txt', 'a') as file:  # 'a' stands for append mode\n",
        "    file.write(\"\\nNormalized Inter-Influence Matrix (N-IIM):\\n\")\n",
        "    for row in n_iim:\n",
        "        # Writing each row in a readable format\n",
        "        row_str = ', '.join([f\"{value:.2f}\" for value in row])\n",
        "        file.write(f\"{row_str}\\n\")\n",
        "\n",
        "print(\"N-IIM has been written to 'solution.txt'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kt6S9-k3PPW-",
        "outputId": "9c51bb03-f36c-4700-ed5a-ce26e67d5245"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N-IIM has been written to 'solution.txt'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate T-IIM (Total Inter-Infuence Matrix)"
      ],
      "metadata": {
        "id": "SSdaSJKaQhL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate an identity matrix of size n x n\n",
        "identity_matrix = np.identity(n)\n",
        "\n",
        "# Calculate (I - n_iim)\n",
        "subtract_matrix = identity_matrix - n_iim\n",
        "try:\n",
        "    # Calculate the inverse of (I - n_iim)\n",
        "    inverse_matrix = np.linalg.inv(subtract_matrix)\n",
        "except np.linalg.LinAlgError:\n",
        "    # Handle the case where the matrix is not invertible\n",
        "    print(\"Error: (I - n_iim) matrix is not invertible.\")\n",
        "    exit()\n",
        "\n",
        "with open('solution.txt', 'a') as file:  # 'a' stands for append mode\n",
        "        file.write(\"\\nInverse of (I - n_iim):\\n\")\n",
        "        for row in inverse_matrix:\n",
        "            row_str = ', '.join([f\"{value:.2f}\" for value in row])\n",
        "            file.write(f\"[{row_str}]\\n\")\n",
        "\n",
        "# Calculate T-IIM: n_iim * (I - n_iim)^-1\n",
        "t_iim =n_iim @ inverse_matrix\n",
        "\n",
        "# Writing to the solution file\n",
        "with open('solution.txt', 'a') as file:  # 'a' stands for append mode\n",
        "    file.write(\"\\nTotal Inter-Influence Matrix (T-IIM):\\n\")\n",
        "    for row in t_iim:\n",
        "        # Writing each row in a readable format\n",
        "        row_str = ', '.join([f\"{value:.2f}\" for value in row])\n",
        "        file.write(f\"{row_str}\\n\")\n",
        "\n",
        "print(\"T-IIM has been written to 'solution.txt'.\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cv48ByVSQkiZ",
        "outputId": "a6bf44d4-f3cc-493a-b8c3-a46610781411"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T-IIM has been written to 'solution.txt'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculating  **α** , **minimum and maximum**\n",
        "\n"
      ],
      "metadata": {
        "id": "3QypL_MSUDrJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the average of all elements in the matrix.\n",
        "α = np.mean(t_iim)+(np.std(t_iim)/2)\n",
        "# Find the maximum and minimum values in the matrix\n",
        "max_t_iim = np.max(t_iim)\n",
        "min_t_iim = np.min(t_iim)\n",
        "\n",
        "\n",
        "with open('solution.txt', 'a') as file:  # 'a' stands for append mode\n",
        "    file.write(\"\\n========================================\\n\")  # For emphasis and separation\n",
        "    file.write(f\"Threshold : {α:.4f}\\n\")\n",
        "    file.write(\"========================================\\n\")  # For emphasis and separation\n",
        "    print(\"Threshold α has been written to 'solution.txt'.\")\n",
        "    file.write(\"\\n========================================\\n\")  # For emphasis and separation\n",
        "    file.write(f\"Minimum : {min_t_iim:.4f}\\n\")\n",
        "    file.write(\"========================================\\n\")  # For emphasis and separation\n",
        "    print(\"Minimum value has been written to 'solution.txt'.\")\n",
        "    file.write(\"\\n========================================\\n\")  # For emphasis and separation\n",
        "    file.write(f\"Maximum : {max_t_iim:.4f}\\n\")\n",
        "    file.write(\"========================================\\n\")  # For emphasis and separation\n",
        "    print(\"Maximum value has been written to 'solution.txt'.\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pz4QwuMoUZ9M",
        "outputId": "164d456c-7cee-4c15-ebf9-93a9fb743ff4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshold α has been written to 'solution.txt'.\n",
            "Minimum value has been written to 'solution.txt'.\n",
            "Maximum value has been written to 'solution.txt'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modified Total Inter-Influence Matrix"
      ],
      "metadata": {
        "id": "5CnEBzZ6zgYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: generate a identity matrix of size similar to t_iim and then sum it with t_iim\n",
        "\n",
        "identity_matrix = np.identity(n)\n",
        "modified_t_iim = t_iim + identity_matrix\n",
        "# Writing to the solution file\n",
        "with open('solution.txt', 'a') as file:  # 'a' stands for append mode\n",
        "    file.write(\"\\nModified Total Inter-Influence Matrix:\\n\")\n",
        "    for row in modified_t_iim:\n",
        "        # Writing each row in a readable format\n",
        "        row_str = ', '.join([f\"{value:.2f}\" for value in row])\n",
        "        file.write(f\"{row_str}\\n\")\n",
        "\n",
        "print(\"Modified T-IIM has been written to 'solution.txt'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3-cyZLxK5Z7",
        "outputId": "5c28a3e0-f0c7-46fd-ee64-e01874a29b95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modified T-IIM has been written to 'solution.txt'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculating Reachability Matrix"
      ],
      "metadata": {
        "id": "sbUeMNdZXeZg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: if modified_t_iim value is greater than alpha then 1 else 0 ... call it reachable matrix\n",
        "\n",
        "reachable_matrix = np.where(modified_t_iim >= α, 1, 0)\n",
        "\n",
        "# Writing to the solution file\n",
        "with open('solution.txt', 'a') as file:  # 'a' stands for append mode\n",
        "    file.write(\"\\nReachability Matrix:\\n\")\n",
        "    for row in reachable_matrix:\n",
        "        # Writing each row in a readable format\n",
        "        row_str = ', '.join([f\"{value}\" for value in row])\n",
        "        file.write(f\"{row_str}\\n\")\n",
        "\n",
        "print(\"Reachability Matrix has been written to 'solution.txt'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwXR2dVjXnJH",
        "outputId": "c813890b-0127-4c40-9430-2afbda32e9d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reachability Matrix has been written to 'solution.txt'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate #influenced, #influent_DA, DAI\n"
      ],
      "metadata": {
        "id": "DqYUvP7EcIdA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "influenced= np.zeros(n, dtype=int)\n",
        "influent_DA= np.zeros(n, dtype=int)\n",
        "# Generate a random Directly Accessible Index (DAI) list with binary values\n",
        "DAI = [1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,0,0]\n",
        "# Count the number of directly accessible factors influencing each factor\n",
        "for i in range(n):\n",
        "        for j in range(n):\n",
        "            if reachable_matrix[i, j] == 1 and i!=j:\n",
        "                    influenced[i] += 1\n",
        "            if reachable_matrix[j,i] == 1 and i!=j and DAI[j]==1:\n",
        "                    influent_DA[i] += 1\n",
        "\n",
        "# Write the results to the file in a tabular form\n",
        "with open('solution.txt', 'a') as file:\n",
        "     file.write(\"+--------+-----+-------------+-------------+\\n\")\n",
        "     file.write(\"| Factor | DAI | #Influenced | #Influent_DA |\\n\")\n",
        "     file.write(\"+--------+-----+-------------+-------------+\\n\")\n",
        "     for i in range(n):\n",
        "        file.write(f\"| {i+1:<6} | {DAI[i]:<3} | {influenced[i]:<11} | {influent_DA[i]:<11} |\\n\")\n",
        "        file.write(\"+--------+-----+-------------+-------------+\\n\")"
      ],
      "metadata": {
        "id": "RwIj7nVzcQMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initial level Partitioning"
      ],
      "metadata": {
        "id": "rV1yY6XEcnXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({\n",
        "        'Factor': np.arange(1,n+1),\n",
        "        'DAI': DAI,\n",
        "        '#Influenced': influenced,\n",
        "        '#Influent_DA': influent_DA\n",
        "    })\n",
        "\n",
        "# Sorting based on the rules provided\n",
        "df.sort_values(by=['#Influent_DA', '#Influenced', 'DAI'], ascending=[True, True, False], inplace=True)\n",
        "\n",
        " # Assign levels and sub-levels\n",
        "df['Level'] = None\n",
        "current_level = 1\n",
        "sublevel_char = 'a'\n",
        "df = df.reset_index(drop=True);\n",
        "for i in range(n):\n",
        "    if i > 0:\n",
        "        same_influent_DA = df.iloc[i]['#Influent_DA'] == df.iloc[i - 1]['#Influent_DA']\n",
        "        same_influenced = df.iloc[i]['#Influenced'] == df.iloc[i - 1]['#Influenced']\n",
        "        same_DAI = df.iloc[i]['DAI'] == df.iloc[i - 1]['DAI']\n",
        "        # print(same_influent_DA,same_influenced,same_DAI)\n",
        "        if not same_influent_DA:\n",
        "            current_level += 1\n",
        "            sublevel_char = 'a'\n",
        "        elif same_influenced and same_DAI:\n",
        "            # same sub-level if all are equal\n",
        "            pass\n",
        "        else:\n",
        "            # next sub-level (a, b, c, ...)\n",
        "            sublevel_char = chr(ord(sublevel_char) + 1)\n",
        "    df.at[i,\"Level\"] = f\"{current_level}-{sublevel_char}\"\n",
        "    # print(df.at[i, 'Level'])\n",
        "df.sort_values(by=['Factor'], ascending=[True], inplace=True)\n",
        "df = df.reset_index(drop=True);\n",
        "print(df)\n",
        "with open(\"solution.txt\", 'a') as file:\n",
        "        file.write(\"Initial Level Partitioning\\n\")\n",
        "        file.write(df.to_string(index=False))\n",
        "        file.write(\"\\n\\n\")\n",
        "print(\"Solution with levels has been written to 'solution_with_levels.txt'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56zN8USLcq6G",
        "outputId": "0bc86800-aec0-4c28-98c5-914eba9f9157"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Factor  DAI  #Influenced  #Influent_DA Level\n",
            "0        1    1            3             3   4-b\n",
            "1        2    1           12            10   9-a\n",
            "2        3    1            7             4   5-b\n",
            "3        4    1            0             0   1-a\n",
            "4        5    1            0             0   1-a\n",
            "5        6    0            7             8   7-a\n",
            "6        7    1            4             2   3-a\n",
            "7        8    1            3             0   1-b\n",
            "8        9    1            9             9   8-a\n",
            "9       10    1            5             4   5-a\n",
            "10      11    1           11             5   6-b\n",
            "11      12    1            2             3   4-a\n",
            "12      13    1            8             5   6-a\n",
            "13      14    1            0             0   1-a\n",
            "14      15    1           10             2   3-b\n",
            "15      16    1            5             1   2-a\n",
            "16      17    0           14            11  10-a\n",
            "17      18    0           14            12  11-a\n",
            "Solution with levels has been written to 'solution_with_levels.txt'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Iterative Level Partitioning\n",
        "\n"
      ],
      "metadata": {
        "id": "EXERFzlxdkQM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# returns 1 if val1>val2 , -1 if val1<val2 and 0 if both are equal\n",
        "def compare_values(val1, val2):\n",
        "    # Splitting the values into numeric and alphabetic parts\n",
        "    num1, alpha1 = val1.split('-')\n",
        "    num2, alpha2 = val2.split('-')\n",
        "\n",
        "    # Convert numeric parts to integers for comparison\n",
        "    num1, num2 = int(num1), int(num2)\n",
        "\n",
        "    # Compare numeric parts\n",
        "    if num1 > num2:\n",
        "        return 1\n",
        "    elif num1 < num2:\n",
        "        return -1\n",
        "    else:\n",
        "        # If numeric parts are equal, compare alphabetic parts\n",
        "        if alpha1 > alpha2:\n",
        "            return 1\n",
        "        elif alpha1 < alpha2:\n",
        "            return -1\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "\n",
        "def recalculate_values(df, RM):\n",
        "    # Recalculating #influent_DA and #influenced based on the current level partitioning\n",
        "    n = len(df)\n",
        "    new_influent_DA = np.zeros(n, dtype=int)\n",
        "    new_influenced = np.zeros(n, dtype=int)\n",
        "\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            if RM[i, j] == 1 and i!=j:\n",
        "                if compare_values(df.at[i, 'Level'] , df.at[j, 'Level'])==-1:\n",
        "                    new_influenced[i] += 1\n",
        "            if RM[j,i] == 1 and i!=j:\n",
        "                if compare_values(df.at[i, 'Level'] ,df.at[j, 'Level'])==1and DAI[j]==1:\n",
        "                    new_influent_DA[i] += 1\n",
        "\n",
        "    df['#Influent_DA'] = new_influent_DA\n",
        "    df['#Influenced'] = new_influenced\n",
        "    return df\n",
        "\n",
        "def assign_levels(df):\n",
        "  # Sorting and assigning levels\n",
        "  df.sort_values(by=['#Influent_DA', '#Influenced', 'DAI'], ascending=[True, True, False], inplace=True)\n",
        "  df['Level'] = None\n",
        "  current_level = 1\n",
        "  sublevel_char = 'a'\n",
        "  df = df.reset_index(drop=True)\n",
        "  for i in range(n):\n",
        "    if i > 0:\n",
        "        same_influent_DA = df.iloc[i]['#Influent_DA'] == df.iloc[i - 1]['#Influent_DA']\n",
        "        same_influenced = df.iloc[i]['#Influenced'] == df.iloc[i - 1]['#Influenced']\n",
        "        same_DAI = df.iloc[i]['DAI'] == df.iloc[i - 1]['DAI']\n",
        "        # print(same_influent_DA,same_influenced,same_DAI)\n",
        "        if not same_influent_DA:\n",
        "            current_level += 1\n",
        "            sublevel_char = 'a'\n",
        "        elif same_influenced and same_DAI:\n",
        "            # same sub-level if all are equal\n",
        "            pass\n",
        "        else:\n",
        "            # next sub-level (a, b, c, ...)\n",
        "            sublevel_char = chr(ord(sublevel_char) + 1)\n",
        "    df.at[i,\"Level\"] = f\"{current_level}-{sublevel_char}\"\n",
        "    # print(df.at[i, 'Level'])\n",
        "  df.sort_values(by=['Factor'], ascending=[True], inplace=True)\n",
        "  df = df.reset_index(drop=True);\n",
        "  return df\n",
        "\n",
        "def perform_iterations(df, RM):\n",
        "  iteration = 0\n",
        "  history = []\n",
        "  i = 1\n",
        "  while i<20:\n",
        "      df = recalculate_values(df, RM)\n",
        "      df = assign_levels(df)\n",
        "      iteration += 1\n",
        "\n",
        "      # Check if the level partitioning has stabilized\n",
        "      if iteration>1:\n",
        "        print(history[-1])\n",
        "\n",
        "      if iteration > 1 and df.equals(history[-1]):\n",
        "          break\n",
        "\n",
        "      history.append(df.copy())\n",
        "      i = i+1;\n",
        "\n",
        "  return history\n",
        "\n",
        "iterations_history = perform_iterations(df, reachable_matrix)\n",
        "df = iterations_history[-1]\n",
        "# Writing the results to 'solution.txt'\n",
        "with open('solution.txt', 'a') as file:\n",
        "    for i, iteration_df in enumerate(iterations_history, start=1):\n",
        "        file.write(f\"Iteration {i}\\n\")\n",
        "        file.write(iteration_df.to_string(index=False))\n",
        "        file.write(\"\\n\\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "rDqGpLqfdrpD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41d9edb8-f58b-46fb-ffd7-a757dc46411f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Factor  DAI  #Influenced  #Influent_DA Level\n",
            "0        1    1            3             1   2-a\n",
            "1        2    1            2            10   7-a\n",
            "2        3    1            7             1   2-c\n",
            "3        4    1            0             0   1-a\n",
            "4        5    1            0             0   1-a\n",
            "5        6    0            4             6   5-a\n",
            "6        7    1            4             0   1-d\n",
            "7        8    1            3             0   1-c\n",
            "8        9    1            3             8   6-a\n",
            "9       10    1            5             1   2-b\n",
            "10      11    1            5             3   4-a\n",
            "11      12    1            2             0   1-b\n",
            "12      13    1            6             2   3-a\n",
            "13      14    1            0             0   1-a\n",
            "14      15    1           10             0   1-f\n",
            "15      16    1            5             0   1-e\n",
            "16      17    0            1            11   8-a\n",
            "17      18    0            0            12   9-a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Factor Ranking Stage"
      ],
      "metadata": {
        "id": "3v1rrmMMPbG1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sub level depth of factors"
      ],
      "metadata": {
        "id": "snViXVFFPeYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_sort(level):\n",
        "    parts = level.split('-')\n",
        "    number = int(parts[0])\n",
        "    letter = parts[1] if len(parts) > 1 else ''\n",
        "    return (number, letter)\n",
        "\n",
        "sorted_df = df.sort_values(by='Level', key=lambda x: x.map(custom_sort))\n",
        "def assign_consecutive_levels(df, level_column='Level'):\n",
        "    \"\"\"\n",
        "    Assigns consecutive integer levels to a DataFrame based on a specified level column.\n",
        "    This function assumes that the DataFrame is already sorted by the level column.\n",
        "    \"\"\"\n",
        "    unique_levels = df[level_column].unique()\n",
        "    level_mapping = {level: i+1 for i, level in enumerate(unique_levels)}\n",
        "\n",
        "    df['SubLevelDepth'] = df[level_column].map(level_mapping)\n",
        "    print(df)\n",
        "    df.sort_values(by=['Factor'], ascending=[True], inplace=True)\n",
        "    return df\n",
        "df = assign_consecutive_levels(sorted_df)\n",
        "with open('solution.txt', 'a') as file:\n",
        "      file.write(f\"Sub Level Depth Of Factors\\n\")\n",
        "      file.write(df.to_string(index=False))\n",
        "      file.write(\"\\n\\n\")\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-wyKRouPi9i",
        "outputId": "2e9e22d3-f332-4f31-a521-aeeb2a084750"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Factor  DAI  #Influenced  #Influent_DA Level  SubLevelDepth\n",
            "3        4    1            0             0   1-a              1\n",
            "4        5    1            0             0   1-a              1\n",
            "13      14    1            0             0   1-a              1\n",
            "11      12    1            2             0   1-b              2\n",
            "7        8    1            3             0   1-c              3\n",
            "6        7    1            4             0   1-d              4\n",
            "15      16    1            5             0   1-e              5\n",
            "14      15    1           10             0   1-f              6\n",
            "0        1    1            3             1   2-a              7\n",
            "9       10    1            5             1   2-b              8\n",
            "2        3    1            7             1   2-c              9\n",
            "12      13    1            6             2   3-a             10\n",
            "10      11    1            5             3   4-a             11\n",
            "5        6    0            4             6   5-a             12\n",
            "8        9    1            3             8   6-a             13\n",
            "1        2    1            2            10   7-a             14\n",
            "16      17    0            1            11   8-a             15\n",
            "17      18    0            0            12   9-a             16\n",
            "    Factor  DAI  #Influenced  #Influent_DA Level  SubLevelDepth\n",
            "0        1    1            3             1   2-a              7\n",
            "1        2    1            2            10   7-a             14\n",
            "2        3    1            7             1   2-c              9\n",
            "3        4    1            0             0   1-a              1\n",
            "4        5    1            0             0   1-a              1\n",
            "5        6    0            4             6   5-a             12\n",
            "6        7    1            4             0   1-d              4\n",
            "7        8    1            3             0   1-c              3\n",
            "8        9    1            3             8   6-a             13\n",
            "9       10    1            5             1   2-b              8\n",
            "10      11    1            5             3   4-a             11\n",
            "11      12    1            2             0   1-b              2\n",
            "12      13    1            6             2   3-a             10\n",
            "13      14    1            0             0   1-a              1\n",
            "14      15    1           10             0   1-f              6\n",
            "15      16    1            5             0   1-e              5\n",
            "16      17    0            1            11   8-a             15\n",
            "17      18    0            0            12   9-a             16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upper Level Drive (uld) and Lower Level Dependence (lldp)"
      ],
      "metadata": {
        "id": "Y1wfkjc0aiOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def influeneced_higher_depth_TIIM(df, TIIM):\n",
        "    sums = []\n",
        "    for index, row in df.iterrows():\n",
        "        current_level = row['Level']\n",
        "        # Sum TIIM values for factors influenced by the current factor and having a higher level\n",
        "        sum_val = sum(TIIM[row['Factor'] - 1, i] for i in range(len(df)) if df.at[i, 'Level'] > current_level)\n",
        "        sums.append(sum_val)\n",
        "    return sums\n",
        "\n",
        "def influent_lower_depth_TIIM(df, TIIM):\n",
        "    sums = []\n",
        "    for index, row in df.iterrows():\n",
        "        current_level = row['Level']\n",
        "        # Sum TIIM values for factors influenced by the current factor and having a higher level\n",
        "        sum_val = sum(TIIM[i,row['Factor'] - 1] for i in range(len(df)) if df.at[i, 'Level'] < current_level)\n",
        "        sums.append(sum_val)\n",
        "    return sums\n",
        "# Apply the function to the DataFrame\n",
        "df['ULD'] = influeneced_higher_depth_TIIM(df, t_iim)\n",
        "df['LLD'] = influent_lower_depth_TIIM(df, t_iim)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2WV7H47a5qY",
        "outputId": "cd708000-6a5b-4239-861f-c85ec1547f0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Factor  DAI  #Influenced  #Influent_DA Level  SubLevelDepth       ULD  \\\n",
            "0        1    1            3             1   2-a              7  1.623923   \n",
            "1        2    1            2            10   7-a             14  0.476587   \n",
            "2        3    1            7             1   2-c              9  1.438237   \n",
            "3        4    1            0             0   1-a              1  1.616010   \n",
            "4        5    1            0             0   1-a              1  1.991570   \n",
            "5        6    0            4             6   5-a             12  0.836452   \n",
            "6        7    1            4             0   1-d              4  2.079077   \n",
            "7        8    1            3             0   1-c              3  2.183703   \n",
            "8        9    1            3             8   6-a             13  0.654545   \n",
            "9       10    1            5             1   2-b              8  1.525301   \n",
            "10      11    1            5             3   4-a             11  1.136714   \n",
            "11      12    1            2             0   1-b              2  2.214701   \n",
            "12      13    1            6             2   3-a             10  1.242897   \n",
            "13      14    1            0             0   1-a              1  1.903257   \n",
            "14      15    1           10             0   1-f              6  1.974594   \n",
            "15      16    1            5             0   1-e              5  2.052095   \n",
            "16      17    0            1            11   8-a             15  0.264147   \n",
            "17      18    0            0            12   9-a             16  0.000000   \n",
            "\n",
            "         LLD  \n",
            "0   1.160447  \n",
            "1   2.786922  \n",
            "2   1.594641  \n",
            "3   0.000000  \n",
            "4   0.000000  \n",
            "5   2.280191  \n",
            "6   0.653310  \n",
            "7   0.422160  \n",
            "8   2.540214  \n",
            "9   1.321620  \n",
            "10  1.961609  \n",
            "11  0.317671  \n",
            "12  1.760543  \n",
            "13  0.000000  \n",
            "14  0.920875  \n",
            "15  0.779680  \n",
            "16  3.187000  \n",
            "17  3.526927  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Total Drive and Total Dependence of Factors"
      ],
      "metadata": {
        "id": "HCvFilKpdjTO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def total_drive(df, TIIM):\n",
        "    sums = []\n",
        "    for index, row in df.iterrows():\n",
        "        # Sum TIIM values for factors influenced by the current factor and having a higher level\n",
        "        sum_val = sum(TIIM[row['Factor'] - 1, i] for i in range(len(df)))\n",
        "        sums.append(sum_val)\n",
        "    return sums\n",
        "\n",
        "def total_dependence(df, TIIM):\n",
        "    sums = []\n",
        "    for index, row in df.iterrows():\n",
        "        current_level = row['Level']\n",
        "        # Sum TIIM values for factors influenced by the current factor and having a higher level\n",
        "        sum_val = sum(TIIM[i,row['Factor'] - 1] for i in range(len(df)))\n",
        "        sums.append(sum_val)\n",
        "    return sums\n",
        "\n",
        "df['TotalDrive'] = total_drive(df,t_iim)\n",
        "df['TotalDependence'] = total_dependence(df,t_iim)"
      ],
      "metadata": {
        "id": "Sop8qnWLeU01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sub Level Index (SLI) Calculation"
      ],
      "metadata": {
        "id": "7ehky6Ccf0Xv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df['SLI'] = [DF/(n-DF+1) for DF in df['SubLevelDepth']]\n",
        "\n",
        "sli_counts = df['SLI'].value_counts()\n",
        "multi_occurrence_sli = sli_counts[sli_counts > 1].index\n",
        "\n",
        "def correct_sli(x):\n",
        "  DF = df['SubLevelDepth'][x]\n",
        "  k = df['SLI'][x] + 0.5*(((DF+1)/(n-DF))-df['SLI'][x])*((df['ULD'][x]/df['TotalDrive'][x])+(df['LLD'][x]/df['TotalDependence'][x]) )\n",
        "  return k\n",
        "# Apply the formula to elements with more than one occurrence, keep original values for others\n",
        "df['IMP_F'] = [correct_sli(i) if df.at[i, 'SLI'] in multi_occurrence_sli else df.at[i, 'SLI'] for i in df.index]\n",
        "df_sorted_for_ranking = df.sort_values(by='IMP_F', ascending=False)\n",
        "df_sorted_for_ranking['Rank'] = range(1, len(df) + 1)\n",
        "\n",
        "# Add the rank back to the original DataFrame\n",
        "df = df.join(df_sorted_for_ranking['Rank'], how='left')\n",
        "with open('solution.txt', 'a') as file:\n",
        "      file.write(f\"Importance Of Factors\\n\")\n",
        "      file.write(df.to_string(index=False))\n",
        "      file.write(\"\\n\\n\")\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vs9eig_Vf5h6",
        "outputId": "5593ddfb-3590-45d4-bcc6-5d1d92c5f70e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Factor  DAI  #Influenced  #Influent_DA Level  SubLevelDepth       ULD  \\\n",
            "0        1    1            3             1   2-a              7  1.623923   \n",
            "1        2    1            2            10   7-a             14  0.476587   \n",
            "2        3    1            7             1   2-c              9  1.438237   \n",
            "3        4    1            0             0   1-a              1  1.616010   \n",
            "4        5    1            0             0   1-a              1  1.991570   \n",
            "5        6    0            4             6   5-a             12  0.836452   \n",
            "6        7    1            4             0   1-d              4  2.079077   \n",
            "7        8    1            3             0   1-c              3  2.183703   \n",
            "8        9    1            3             8   6-a             13  0.654545   \n",
            "9       10    1            5             1   2-b              8  1.525301   \n",
            "10      11    1            5             3   4-a             11  1.136714   \n",
            "11      12    1            2             0   1-b              2  2.214701   \n",
            "12      13    1            6             2   3-a             10  1.242897   \n",
            "13      14    1            0             0   1-a              1  1.903257   \n",
            "14      15    1           10             0   1-f              6  1.974594   \n",
            "15      16    1            5             0   1-e              5  2.052095   \n",
            "16      17    0            1            11   8-a             15  0.264147   \n",
            "17      18    0            0            12   9-a             16  0.000000   \n",
            "\n",
            "         LLD  TotalDrive  TotalDependence       SLI     IMP_F  Rank  \n",
            "0   1.160447    2.830055         3.025019  0.583333  0.583333    10  \n",
            "1   2.786922    3.509689         3.469998  2.800000  2.800000     3  \n",
            "2   1.594641    3.173505         3.198559  0.900000  0.900000     8  \n",
            "3   0.000000    1.827837         1.501286  0.055556  0.083003    18  \n",
            "4   0.000000    2.249858         1.917751  0.055556  0.083037    17  \n",
            "5   2.280191    3.079718         3.364107  1.714286  1.714286     5  \n",
            "6   0.653310    2.815644         2.881760  0.266667  0.266667    13  \n",
            "7   0.422160    2.730258         2.645566  0.187500  0.187500    14  \n",
            "8   2.540214    3.141669         3.440758  2.166667  2.166667     4  \n",
            "9   1.321620    2.911502         3.055485  0.727273  0.727273     9  \n",
            "10  1.961609    3.407257         3.206287  1.375000  1.375000     6  \n",
            "11  0.317671    2.591984         2.998264  0.117647  0.117647    15  \n",
            "12  1.760543    3.095665         3.204825  1.111111  1.111111     7  \n",
            "13  0.000000    2.104123         2.181159  0.055556  0.083638    16  \n",
            "14  0.920875    3.039519         2.928546  0.461538  0.461538    11  \n",
            "15  0.779680    2.983657         2.862604  0.357143  0.357143    12  \n",
            "16  3.187000    3.819594         3.665022  3.750000  3.750000     2  \n",
            "17  3.526927    3.982894         3.747434  5.333333  5.333333     1  \n"
          ]
        }
      ]
    }
  ]
}